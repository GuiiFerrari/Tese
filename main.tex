\documentclass[12pt]{report}
\usepackage[a4paper, margin=2cm, footskip=15pt]{geometry}
\usepackage[utf8]{inputenc}
%\usepackage[ngerman]{babel}
\usepackage[export]{adjustbox}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{amsmath}
\usepackage{pgfplots}
% \usepackage{unicode-math}
\newcommand\mathplus{+}
% \usepackage{subfigure}
% \usepackage{algorithm}
% \usepackage[ruled,vlined,lined,linesnumbered,spanish, onelanguage]{algorithm2e}
\usepackage[ruled,vlined,lined,linesnumbered,portuguese, onelanguage]{algorithm2e}
% \usepackage{algorithmic}
\usepackage{algpseudocode}
\renewcommand{\baselinestretch}{1.3}
\usepackage[backend=bibtex, style=numeric, sorting=none]{biblatex}
%\usepackage{natbib}
%\bibliographystyle{unsrt}
% \usepackage[backend=biber, style=numeric, sorting=none]{biblatex}
%\addbibresource{sample.bib}
% \bibliographystyle{plain}
%\renewcommand{\listalgorithm}{Lista de Algoritmos}%
%\renewcommand{\algorithm}{Algoritmo}%
%\renewcommand{\algocf@typo}{}%
%\renewcommand{\@algocf@procname}{Procedimento}
%\renewcommand{\@algocf@funcname}{Fun\c{c}\~{a}o}
\usepackage[scr=rsfs]{mathalpha}
\DeclareMathOperator{\sinc}{sinc}
\DeclareMathOperator{\rect}{rect}

\usepackage{hyperref}
\hypersetup{colorlinks=false, pdftitle={Relatório de Atividades}}
%\usepackage[backend=biber]{biblatex}
\addbibresource{sample.bib}





\begin{document}

\captionsetup[figure]{name={Figura}}
\renewcommand*\contentsname{Sumário}
\renewcommand{\listfigurename}{Lista de figuras}
\renewcommand{\listoftables}{Tabelas}
\renewcommand{\listofalgorithms}{Lista de algoritmos}
\makeatletter
\renewcommand{\@chapapp}{Capítulo}
\makeatother



\begin{titlepage}
\begin{center}
\large{Instituto de Física da USP}\\[0.4cm]
\begin{doublespacing}\textbf{\huge{Desenvolvimento de Ferramentas de Machine Learning para Estudos de Reações Nucleares em Alvos Ativos}}\\[0.8cm]
\end{doublespacing}
\large{Relatório de atividades do projeto de pesquisa de mestrado referente ao período de fevereiro à dezembro de 2020} \\ [5.1cm]
\end{center}

\begin{flushleft}\large{Guilherme Ferrari Fortino  (Bolsista)}\\[0.7cm]\end{flushleft}
\large{Valdir Guimarães \par Professor Dr. no Instituto de Física da USP (Orientador)}\\[0.7cm]
\large{Juan Carlos Zamora Cardona \par Pós-doutorando no Instituto de Física da USP (Coorientador)} \\ [5.5cm]
\begin{center}
\large{São Paulo}\\ [0.2cm]
\large{2020}
\end{center}
\end{titlepage}
\newpage

\tableofcontents
\listoffigures
\listoftables
\listofalgorithms
\newpage

\chapter{Introdução}

\par Um dos principais objetivos do estudo em física nuclear é entender a estrutura do núcleo. Apesar do sucesso do modelo de camadas em explicar as estruturas de núcleos estáveis, os núcleos instáveis ou exóticos, ricos ou pobres em nêutrons, continuam sendo um grande desafio para nossa compreensão.

\par Os núcleos leves radioativos são de grande interesse para a astrofísica nuclear. 

\par Experimentos para o estudo desses núcleos 

\chapter{Uma breve introdução ao \textit{Machine Learning}}\label{sec:ml}

\par \textit{Machine learning} é a área de estudo que desenvolve algoritmos para que eles possam aprender com os dados, sem serem explicitamente programados para isso\cite{mlbook}. Supõe-se que uma rede neural imite um sistema biológico, em que os neurônios interajam enviando sinais na forma de funções matemáticas entre as camadas. Isso inspirou um modelo matemático simples para um neurônio artificial:

\begin{equation}
    y = f\left(\sum^{n}_{i = 1}\omega_i x_i + bi\right) = f(z),
\end{equation}

\par onde $y$ é a saída do neurônio, que corresponde à função de ativação $f$ que depende da soma ponderada, onde o peso é $\omega_i$, das entradas $x_i$ dos outros $n$ neurônios. O termo $b_i$ corresponde ao parâmetro \textit{bias}. A ideia é fazer um neurônio receber a informação de todos os outros neurônios da camada anterior, fazendo uma média ponderada (onde o peso que será estimado pelo algoritmo de \textit{machine learning}) e somando com um termo independente (\textit{bias}, que também é estimado). Os parâmetros $\omega_i$ e $b_i$ serão estimados através de um determinado procedimento, chamado de treino.

\section{Tipos de redes neurais}

\par Uma rede neural artificial, \textit{Artificial Neural Network} (ANN), é um modelo computacional que consiste de camadas de neurônios. Muitas ANN's foram desenvolvidas, mas a maioria consiste em uma camada de entrada (\textit{input layer}), uma camada de saída (\textit{output layer}) e eventuais camadas entre essas duas, chamadas de camadas ocultas (\textit{hidden layers}). Os tipos mais comuns são:

\subsubsection*{Feed-Forward Neural Networks}

\par A \textit{Feed-forward neural networks} (FFNN) é a primeira e mais simples rede neural desenvolvida. Nessa rede a informação se move apenas para frente através das camadas (da camada de entrada até a camada de saída). A figura \ref{fig:FFNN} mostra a representação da rede, onde os neurônios são representados por círculos, enquanto que as linhas mostram as conexões entre os neurônios. Cada neurônio recebe informação de todos os neurônios da camada anterior, portanto a rede é chada de totalmente conectada, \textit{fully-connected} (FC), FFNN.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.55]{figs/FFNN.png}
    \caption{Exemplo de FFNN. A camada de entrada na esquerda propaga a informação para a direita (camada de saída). Todos os neurônios entre camadas estão conectados entre si.}
    \label{fig:FFNN}
\end{figure}

\subsubsection*{Convolutional Neural Network}

\par Uma variante da FFNN é a chamada de rede neural convolucional, \textit{convolutional neural network} (CNN). Do ponto de vista matemático sobre convoluções, a convolução descrita como $(f*g)(t)$ de uma função $f(t)$ e outra $g(t)$ é definida como:

\begin{equation}\label{eq:conv_cont}
    (f*g)(t) \equiv \int^{\infty}_{\infty} f(\tau)g(t - \tau)d\tau.
\end{equation}

Para o caso discreto, com $g$ sendo uma função resposta finita de tamanho $2M$, temos

\begin{equation}\label{eq:conv_disc}
    (f*g)[n] = \sum^{M}_{m = -M} f[n - m]g[m]. 
\end{equation}

\par Convoluções são invariantes sobre rotação e translação, portanto são muito utilizadas para processamento de sinais e imagens\cite{signal_book}. Para a convolução discreta se escolhe um filtro que irá atuar no vetor desejado. Para ilustrar o que significa isso, no caso discreto e unidimensional, a figura \ref{fig:conv_valid} mostra o processo de convolução de um vetor de tamanho 9 e um filtro de tamanho 3.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.38]{figs/conv_valid.png}
    \caption{Processo de convolução entre sinal azul em cima e o filtro em verde, resultando no sinal azul embaixo.}
    \label{fig:conv_valid}
\end{figure}

\par Percebe-se que o sinal resultante tem dimensão menor que o sinal original. O filtro (também chamado de \textit{kernel}) atua em um ponto que possua vizinhos o suficiente para o restante do filtro poder fazer a multiplicação ponto a ponto. Esse tipo de convolução tem o chamado emparelhamento válido (\textit{valid padding}). O tamanho $n_2$ resultante do vetor de saída é 
\begin{equation}
    n_2 = n_1 - m + 1,
\end{equation}

\par onde $n_1$ é o tamanho do vetor de entrada e $m$ o tamanho do filtro (\textit{kernel size}). Para que o vetor de saída tenha o mesmo tamanho do vetor de entrada, são acrescentados zeros em torno da entrada, de forma que a saída tenha o mesmo tamanho da entrada. Esse é o chamado emparelhamento igual (\textit{same padding}). A figura \ref{fig:conv_same} ilustra esse processo.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.33]{figs/conv_same.png}
    \caption{Processo de convolução entre o sinal azul em cima e o filtro em verde, resultando no sinal azul embaixo. Agora são acrescentados zeros no inicio e no final do vetor para que o vetor saída tenha o mesmo tamanho do vetor de entrada (nesse caso 9).}
    \label{fig:conv_same}
\end{figure}

\par Uma CNN é capaz de fazer convoluções. Como estamos no contexto de inteligência artificial, \textit{a priori} não sabemos quais os valores dos filtros que devem ser aplicados, apenas seus tamanhos e como agem. A ideia é estimar os valores do filtro, através do treino da rede neural, que deve ser aplicado para se obter o resultado desejado.

\par Cada filtro aplicado gera um mapa característico (\textit{feature map}), que é o resultado da atuação do filtro em um vetor. Usualmente em uma CNN se escolhe o tamanho do filtro, \textit{padding} (\textit{valid} ou \textit{same}) e quantos filtros serão aplicados (para saber quantos \textit{feature maps} serão gerados). Os filtros têm seus valores estimados pelo treino da rede neural, gerando vários mapas (\textit{feature maps}). Como temos vários mapas, isso acarreta em um aumento de dimensionalidade. Para filtrar/selecionar os mapas é usado um critério, como por exemplo selecionar valores máximos dos mapas gerados dada uma janela de atuação (quantos mapas serão comparados para selecionar o máximo valor). O \textit{Max-Pooling} faz isso, selecionando valores máximos para uma determinada quantidade de mapas sendo comparados (\textit{pool size}).

\par Existem outros tipos de redes neurais, porém não serão discutidas aqui.

\section{Construindo uma rede neural}

\par Para a construção de uma rede neural (nesse caso em específico de uma rede neural supervisionada, que será discutida mais para frente), precisamos primeiro entender sobre os dados que estamos trabalhando. A maioria das redes neurais possuem um \textit{input} que deve ter dimensão fixa, ou seja, todos os dados devem ter o mesmo formato. O mesmo vale para o \textit{output}.

\par Para cada camada da arquitetura devemos escolher sua função de ativação. Tanto FNNN's quanto CNN's podem possuir funções de ativação. Dentre muitas funções de ativação podemos citar a \textit{Rectified Linear Units} (ReLU)\cite{RELU}, sigmoide, linear, tangente hiperbólica etc. A figura \ref{fig:ativacoes} mostra os gráficos dessas funções de ativação.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.7]{figs/ativacoes.png}
    \caption{Funções de ativação e seus respectivos gráficos.}
    \label{fig:ativacoes}
\end{figure}

\par O próximo passo é definir a função custo (também chamada de \textit{loss}) e o otimizador. A função custo tem o papel de retornar valores altos para previsões erradas e valores baixos para previsões corretas. Por exemplo, se queremos treinar uma rede neural para classificação binária (que prevê, devemos usar a função custo chamada de \textit{binary cross-entropy} dada por

\begin{equation}\label{eq:binary_cross_entropy}
    C(p(y_i)) = -\frac{1}{N}\sum_{i = 1} ^N y_i \log(p(y_i)) + (1 - y_i)\log(1 - p(y_i)),
\end{equation}

\par onde $y_i$ é o rótulo (\textit{label}), $p(y_i)$ é a probabilidade do ponto $y_i$ ser 1 e $N$ é o número de pontos. O objetivo da rede neural é achar o mínimo da função $C(p(y_i))$, o que implica diretamente na melhor solução para o conjunto de dados. Isso é feito pelo método de retropropagação do erro (\textit{backpropagation}) por um otimizador. Outros exemplos de \textit{loss} são: erro quadrático médio, \textit{categorical cross-entropy} etc.

\par O otimizador tem o objetivo de otimizar os parâmetros presentes na rede neural, buscando o mínimo global da função custo, o que nem sempre acontece, pois a minimização pode parar em um mínimo local da função. Existem diversos otimizadores, como por exemplo o \textit{Stochastic Gradient Descent} (SGD), ADAM, ADAMAX etc. Para o SGD temos que a atualização de parâmetros é dada por

\begin{equation}\label{eq:SGD}
    \theta_j = \theta_{j} - \alpha \frac{\partial }{\partial \theta_j}C(\theta),
\end{equation}

\par onde $\theta_j$ é o parâmetro a ser atualizado, $\alpha$ é a \textit{learning rate} e $C(\theta)$ é a \textit{loss} que depende dos parâmetros.

\par Para enfim treinar a rede neural, se escolhe o \textit{batch size}, que é o tamanho de amostras que irá será usada para o treino, por iteração em cada rodada de treino (\textit{epoch}). Por exemplo, se usamos 1000 dados para o treino, e o \textit{batch size} é 500, cada \textit{epoch} terá duas iterações. No geral se usam \textit{batch sizes} pequenos, pois o consumo de memória é mais eficiente.

\par Para avaliação do modelo se usam dados de validação, que servem para verificar o comportamento da rede neural que está sendo treinada em dados que não são usados para treino, a fim de verificar problemas, como por exemplo o \textit{overfit}, que ocorre quando a rede neural começa a se adequar perfeitamente aos dados de treino, perdendo a capacidade de previsão em dados que não estão sendo vistos pela rede neural.

\par Além dos dados de validação podemos escolher métricas que auxiliam a visualização do treino e nos retornam informações importantes sobre sua qualidade. Exemplos importantes de métricas são: acurácia binária, erro médio absoluto, acurácia categórica, falsos positivos etc. Tudo depende do objetivo da rede neural.

\section{Sistemas de \textit{machine learning}}

Podemos dividir os tipos de sistemas de \textit{machine learning} em quatro tipos:

\subsubsection*{Aprendizado Supervisionado}
% \begin{enumerate}
%     \item aprendizado supervisionado;
%     \item aprendizado não supervisionado;
%     \item aprendizado semi supervisionado;
%     \item aprendizado por reforço.
% \end{enumerate}

\par Aprendizado supervisionado é quando fornecemos para a rede neural um conjunto de dados para o treino com a solução desejada (chamados de \textit{labels}). Um uso típico é para problemas de classificação. Por exemplo, classificação de imagens (identificação de figuras), previsão de valores numéricos etc. Exemplos de de algoritmos supervisionados são:

\begin{itemize}
    \item \textit{k-Nearest Neighbors}\cite{knn}
    \item Regressão linear
    \item \textit{Support Vector Machines} (SVMs)
    \item \textit{Decision Trees} and \textit{Random Forests}
    \item Redes neurais
\end{itemize}

\subsubsection*{Aprendizado não supervisionado}

\par Aprendizado não supervisionado é quando fornecemos o conjunto de dados para o treino, porém sem solução. A ideia é aprender sem supervisão. Um problema comum, por exemplo, é quando queremos identificar \textit{clusters} em um conjunto de dados (\textit{clustering}).

\subsubsection*{Aprendizado semi supervisionado}

\par Aprendizado supervisionado é quando apenas parte do conjunto de dados para o treino possui \textit{labels}. Isso é comum quando se obtém conjuntos de dados diferentes e apenas parte deles foi classificado.

\subsubsection*{Aprendizado por reforço}

\par Aprendizado por reforço é quando um sistema, chamado de \textit{agente} nesse contexto, aprende através do ambiente, realizando ações que maximizam sua recompensa. Por exemplo, caso o sistema realize uma ação incorreta, ele recebe uma penalidade, fazendo com que procure outra maneira de realizar a ação, dessa vez de maneira correta, para poder ganhar uma recompensa. Esse tipo de sistema é muito usado, por exemplo, em automatização robótica, como carros que pilotam sozinhos, robôs que aprendem a andar etc.

\section{Aplicações de \textit{machine learning} na física nuclear}

\par Em física nuclear, o uso de técnicas de \textit{machine learning} tem se mostrado cada vez mais importante. Podemos citar alguns exemplos de uso em:

\subsubsection*{Estudo de propriedades de núcleos}

\par É possível estimar propriedades de núcleos usando modelos e dados experimentais já existentes. Dada a capacidade de redes neurais de aprenderem padrões não lineares nos dados, isso tem se mostrado uma alternativa para estimar propriedades dos núcleos como: raio de carga nuclear \cite{raio_carga}, massa de núcleos \cite{nuclear_mass} etc. 

\subsubsection*{Decaimento beta e processo-$r$}

\par O decaimento $\beta$ é fundamental para entender a origem dos elementos pesados. Prever o tempo de meia vida do decaimento $\beta$ é de grande importância para simulações do processo-$r$ (caputra rápida de nêutrons). Com redes neurais é possível fazer previsões que levam em conta a vida do problema, como visto na Ref. \cite{mlbetadecay}.  A figura [xx] mostra a previsão do tempo de meia vida ($T_{1/2}$) do decaimento $\beta$ (em segundos) para isótonos com número de nêutrons N = 126.

\subsubsection*{Alvos ativos}

\par Experimentos com alvos ativos (que será discutido nos próximos capítulos) geram enormes quantidades de dados, o que gera a necessidade do uso de algoritmos de \textit{machine learning} para diminuir o consumo em tempo. Além disso são geradas nuvens de pontos tridimensionais, o que demanda um grande trabalho do ponto de vista de visão computacional, com algoritmos capazes de identificar estruturas em três dimensões. A figura [xx] mostra exe

\par Com essa breve descrição sobre \textit{machine learning} podemos seguir adiante e entender seu uso dentro deste trabalho, que será feito nos próximos capítulos.





\chapter{O experimento}\label{PATTPC}

\par O prototype Active Target - Time Projection Chamber (pAT-TPC) é um detector de alvo-ativo que usa o volume de gás tanto quanto alvo quanto como detector. Seu grande volume ativo e capacidade de \textit{tracking} fornecem boa resolução energética e  angular, o que torna o pAT-TPC adequado para trabalhar com feixes exóticos de baixa intensidade\cite{pattpc, pattpc2}. O feixe secundário de $^{17}$F usado pelo pAT-TPC é produzido pelo \textit{Twin Solenoids} (TWINSOL) \cite{twinsol}. A figura \ref{fig:twinsol+pattpc} mostra os dois sistemas acoplados.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.38]{figs/poster3.jpeg}
    \caption{Sistema TWINSOL à esquerda e pAT-TPC à direita. Todo o sistema está localizado na University of Notre Dame.}
    \label{fig:twinsol+pattpc}
\end{figure}

\par Essa seção irá descrever brevemente o pAT-TPC, bem como o TWINSOL. Descrições mais detalhadas podem ser encontradas nas referências \cite{pattpc, twinsol}.

% \section{Produção do feixe de $^{17}$F}
\section{O sistema TWINSOL}

\par O TWINSOL é um sistema de produção de feixes radioativos de baixa intensidade que possui dois solenoides supercondutores alinhados que são usados para produzir, coletar, transportar, focar e analisar feixes estáveis e radioativos.

\par Cada solenoide possui 30 cm de raio interno e 1 m de comprimento. O fato de ser um solenoide finito faz com que surjam efeitos de borda na componente radial do campo magnético do solenoide, cujo efeito faz com que o solenoide seja capaz de focalizar partículas. A figura \ref{fig:campo_mag} mostra um exemplo de calculo do valor do campo magnético, usando valores do sistema ``irmão" do TWINSOL, o Radioactive Ion Beams in Brasil (RIBRAS) \cite{ribras}, para as componentes $x$, $y$ e $z$. É nítido que o campo em $z$ permanece praticamente constante e próximo das extremidades da bobina (linha vertical tracejada preta), $B_x$ e $B_y$ crescem em módulo, fazendo com que o solenoide funcione como uma lente delgada.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.85]{figs/Campo_mag.png}
    \caption{Valor do campo magnético $B$ em T em função da posição em $z$ em cm da bobina. A linha vertical tracejada preta indica o limite físico da bobina. O campo foi calculado à uma distância de 8 cm do eixo do solenoide. É possível ver claramente o efeito de borda que há em um solenoide finito.}
    \label{fig:campo_mag}
\end{figure}

\par A trajetória das partículas dentro do solenoide é helicoidal e, como os solenoides funcionam como uma lente, é possível calibrar o ponto focal. O foco depende da rigidez magnética da partícula através da relação:

\begin{equation}
    \frac{1}{f} = \frac{B_z ^2}{(B\rho)^2},
\end{equation}

onde $f$ é o ponto focal, $B_z$ a componente $z$ do campo magnético, e $B\rho$ é dado por:

\begin{equation}
    B\rho = \frac{mv}{q} = \frac{\sqrt{2mE}}{q},
\end{equation}

onde $E$ é a energia, $m$ sua massa e $q$ seu estado de carga. A figura \ref{fig:ribras_sol_sim_a} mostra a simulação, usando o GEANT4\cite{geant4}, usando novamente valores do RIBRAS, da trajetória das partículas dentro do solenoide e em \ref{fig:ribras_sol_sim_b} pode-se ver que o feixe é focalizado em um ponto.

\begin{figure}[H]
\centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[scale=0.5]{figs/ribras_1.png}
        \caption{Simulação que mostra as trajetórias helicoidais das partículas em laranja dentro do solenoide de cor verde até colidirem em um plano vermelho.}
        \label{fig:ribras_sol_sim_a}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[scale=0.6]{figs/ribras_2.png}
        \caption{Partículas em laranja passam pelo solenoide de cor verde que funciona como lente, sendo focalizadas em ponto da linha vermelha à esquerda da figura.}
        \label{fig:ribras_sol_sim_b} 
    \end{subfigure}
\caption{Simulações computacionais usando o GEANT4 para entender o comportamento de partículas carregas que passam por um solenoide supercondutor.}
\label{fig:sim_ribras}
\end{figure}

% Figura a 1 sol, figura b mostra ponto focal

\par Sabendo então das propriedades do sistema, podemos produzir então feixes radioativos. Para produzir $^{17}$F uma célula gasosa preenchida com deutério é bombardeada por um feixe de $^{16}$O. Não há só a reação que produz $^{17}$F, temos as reações: $^{16}$O(d, n)$^{17}$F, $^{16}$O(d, p)$^{17}$O e também o feixe de $^{16}$O pode ser apenas espalhado. Outras reações, por exemplo, com a estrutura da célula gasosa (janela feita de 5 $\mu$m de titânio) podem ocorrer, mas o papel do TWINSOL é de selecionar e focalizar apenas as partículas desejadas.

\par Um problema comum é de que, mesmo para partículas diferentes, o $B_{\rho}$ possa ser muito próximo ou igual. Isso faz com que não seja possível obter um feixe de $^{17}$F com 100\% de pureza. O feixe produzido possui 54 \% de $^{17}$F, 41 \% de $^{17}$O e cerca de 5 \% de $^{16}$O. Por fim, o feixe produzido pelo TWINSOL é conduzido até o pAT-TPC.

\section{O alvo ativo pAT-TPC}

\par A figura \ref{subfig:pattpc} mostra o desenho esquemático do pAT-TPC. O detector possui uma cela cilíndrica de 50 cm de comprimento e 28 cm de diâmetro, onde o seu eixo é alinhado com o eixo do feixe. A câmara é preenchida com  o $^4$He puro gasoso à uma pressão de 350 Torr que serve tanto quanto alvo de reação quanto meio detector. Tanto o feixe quanto partículas originadas da reação ionizam o gás e os elétrons que surgem dessa ionização são conduzidos por um campo elétrico de 1 kV/cm perpendicular ao eixo da câmara até o detector (\textit{pad plane}), o \textit{Micromegas}\cite{micromegas}, mostrado na figura \ref{subfig:micromegas}.

\begin{figure}[H]
\centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[scale=0.32]{figs/pattpc.png}
        \caption{Visão transversal do pAT-TPC. O gás é preenchido dentro da cela que possui um campo elétrico perpendicular ao plano do  \textit{Micromegas}.}
        \label{subfig:pattpc}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics[scale=0.32]{figs/micromegas.png}
        \caption{Foto do \textit{Micromegas}. O detector é multipixelado com uma maior densidade no centro, parte destacada na imagem, pois seu ganho é menor para não queimar os canais centrais. O \textit{pad} central tem diâmetro de 5 mm enquanto que as faixas coaxiais possuem passo de 2mm. Os \textit{pads} são separados por um intervalo de 0.25 mm.}
        \label{subfig:micromegas} 
    \end{subfigure}
\caption{Figura esquemática do pAT-TPC e o detector \textit{Micromegas}\cite{pattpc}.}
\label{fig:pattpc_e_micromegas}
\end{figure}

\par O \textit{Micromegas} é um dispositivo de amplificação de elétrons, que consiste em um rede com 2048 canais triangulares feitos em ouro em que cada canal possui uma eletrônica independente. O formato triangular dos canais tem como objetivo maximizar a resolução espacial do detector. Cada canal possui uma posição ($x$, $y$) fixa e a terceira coordenada $z$ será determinada a partir do tempo de voo da partícula. Isso só é possível pois a velocidade de drift dos elétrons é constante\cite{drift_constant}, portanto a posição em $z$ da partícula é diretamente proporcional ao tempo de voo. Esse princípio que deu origem ao nome de \textit{Time Projection Chamber}, pois o evento é projetado no tempo. A equação  \ref{eq:langevin} (equação de Langevin) descreve o movimento de um elétron com massa $m$ e carga $e$ é descrito por

\begin{equation}\label{eq:langevin}
    m\frac{d\vec{v}}{dt} = e\left(\vec{E} +\vec{v}\times \vec{B}\right) - \frac{m}{\tau}\vec{v},
\end{equation}

onde $\vec{E}$ é o vetor campo elétrico, $\vec{B}$ o vetor campo magnético, $\vec{v}$ é o vetor de velocidade do elétron e $\tau$ é o tempo de colisão médio, que depende das propriedades termodinâmicas do gás. No caso do pAT-TPC, $\vec{B}$ é zero e a solução estacionária para a velocidade de drift do elétron é

\begin{equation}
    \vec{v} = \frac{\tau}{m}e\vec{E}.
\end{equation}

\par A velocidade de drift depende das propriedades termodinâmicas do gás (temperatura, pressão) e também de sua condutividade elétrica. Isso significa que é a calibração da velocidade envolve a calibração não só do campo elétrico, mas também do gás dentro do TPC. A conversão para a coordenada \textit{z} é linear, portanto no tempo \textit{t} = 0 o elétron está no plano do detector.

\par O \textit{Micromegas} amplifica o sinal usando \textit{thick gems}. \textit{Thick gems} usam do fato de que, no momento em que o elétron passa para uma região de campo elétrico ordens de grandeza maior que de sua origem, ocorre a ionização secundária (quando o elétron ioniza o gás). Isso provoca o que é chamado de avalanche de elétrons, amplificando a intensidade do sinal recebido. A figura \ref{fig:thick_gems} mostra a esquematização do \textit{Micromegas}.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.45]{figs/thick_gems.png}
    \caption{Plano do \textit{Micromegas} com a esquematização das \textit{thick gems}. Os elétrons quando passam para um campo elétrico mais intenso ionizam o gás, produzindo ainda mais elétrons (evento chamado de avalanche de elétrons).}
    \label{fig:thick_gems}
\end{figure}

\par Nem todos os \textit{pads} do detector são ativados por evento. Existem canais auxiliares que servem para evitar armazenar canais sem detecção. Caso haja detecção além do centro do \textit{Micromegas} então os sinais gerados pelo evento são armazenados. São gerados cerca de 300 sinais por evento, sendo que existem milhões de eventos, o que gera a necessidade de desenvolvimento de algoritmos extremamente eficientes em tempo para a análise. Para analise completa do experimento precisamos seguir as seguintes etapas:

\begin{itemize}
    \item Reconstruir os eventos tridimensionais (nuvens de pontos) a partir dos sinais gerados pelo \textit{micromegas}. Isso inclui remover o fundo, localizar todos os pontos de interação das partículas carregas com o gás etc. Isso será mostrado em detalhes no capítulo \ref{sec:sinais};
    \item A partir das nuvens de pontos é necessário reconstruir a cinemática das reações, identificando trajetórias das partículas e o vértice de reação;
    \item Com a cinemática reconstruída podemos associar as partículas com as trajetórias e finalmente construir as seções de choque. 
\end{itemize}

As análises dos pulsos, reconstituição de eventos e resultados serão mostradas nos próximos capítulos.

\chapter{Reconstrução de nuvens de pontos}\label{sec:sinais}

\par Esse capítulo irá mostrar como são recriadas as nuvens de pontos (\textit{pointclouds}) a partir dos pulsos gerados por cada pixel do \textit{micromegas}. Primeiro será mostrado como os sinais são analisados a partir de métodos mais tradicionais e depois usando algoritmos de \textit{machine learning}.


% \paA quantidade de histogramas armazenados ultrapassa facilmente a casa das centenas de milhões, portanto é necessário o desenvolvimento de algoritmos extremamente rápidos para a análise.

\par 

\section{Análise dos pulsos com algoritmos tradicionais}

\par Para a reconstituição dos eventos devemos analisar os sinais dos canais do \textit{micromegas}. Cada canal possui eletrônica independente e os sinais recebidos são como os mostrados na figura \ref{fig:exemplos_sinais}.

\begin{figure}[H]
\centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.44]{figs/ex_sinal_1.png}
        \caption{}
        \label{subfig:exemplos_sinais_1}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.44]{figs/ex_sinal_2.png}
        \caption{}
        \label{subfig:exemplos_sinais_2}
    \end{subfigure}
\caption{Exemplos de sinais produzidos pelos canais do detector. Em \ref{subfig:exemplos_sinais_1} o sinal possui apenas um pulso, enquanto em \ref{subfig:exemplos_sinais_2} há vários pulsos em sobreposição, formando um único pulso com largura maior que em \ref{subfig:exemplos_sinais_1}.}
\label{fig:exemplos_sinais}
\end{figure}

\par No eixo $x$, cada um dos 512 \textit{time buckets} possui largura de 195 $n s$. No eixo $y$ temos a carga acumulada no detector para cada \textit{time bucket}. Em \ref{subfig:exemplos_sinais_1} vemos um sinal com um pedestal (fundo ou \textit{baseline}) com altura entre 300 e 450, e um pulso estreito em cima. Como dito na seção \ref{PATTPC}, os elétrons que surgem da ionização do gás são conduzidos perpendicularmente pelo campo elétrico até o detector. A interação da partícula com o gás é evidenciada justamente pelo pulso presente em \ref{subfig:exemplos_sinais_1}. Cada pixel $i$ do detector está em uma posição ($x_i$, $y_i$), o centroide de cada gaussiana fornece a coordenada em $t$ (\textit{bucket}) para então ser convertida na posição em $z$ da partícula detectada, e a carga do ponto é a área do pulso (gaussiana com centroide $t$) sem a \textit{baseline}.

\par Para \ref{subfig:exemplos_sinais_1} temos apenas um pulso, o que significa que há um feixe paralelo àquele canal do histograma, afinal, temos apenas um único ponto ($x$, $y$, $z$). Já para \ref{subfig:exemplos_sinais_2} temos o que é chamado de \textit{gaussian mixture}, que é a presença de várias gaussianas sobrepostas. Esse tipo de sinal corresponde ao feixe indo perpendicularmente ao pixel do detector. A ilustração desse problema está na figura \ref{fig:get_signal}, que mostra o processo da passagem de uma partícula carregada e como o sinal é gerado a partir disso. As gaussianas presentes em \ref{subfig:exemplos_sinais_2} devem ter a mesma largura da gaussiana presente em \ref{subfig:exemplos_sinais_1}. 

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.325]{figs/get.png}
    \caption{Ilustração que mostra a variação no formato da carga coletada a partir da passagem de uma partícula carregada dentro do TPC, onde o plano do detector está embaixo. No lado esquerdo de cada imagem, a distribuição do sinal coletado por um único pad (escuro) do plano de coleta é mostrado (o canal eletrônico de leitura é representado pela seta cinza em negrito). No caso de uma trajetória quase horizontal (a), o sinal é uma distribuição estreita, enquanto para uma trajetória próxima a uma direção vertical (b), a distribuição deve ser muito mais ampla (vários picos devem ser extraídos desse sinal). A última imagem ilustra o caso em mais de uma trajetória de partículas contribui para o sinal\cite{GET}.}
    \label{fig:get_signal}
\end{figure}

\par Para analisar os pulsos devemos então remover a \textit{baseline} dos sinais. O fundo não é trivial de se determinar, pois não é analítico, oscilando muito entre os canais.

\subsection{Remoção do fundo}

A primeira tentativa de estimar o sinal sem o fundo é usando transformada de Fourier e um filtro passa-baixa. Seja $f(t)$ uma função qualquer, sua transformada de Fourier é dada por

\begin{equation} \label{eq:fourier}
    \hat{f}(v)=\mathscr{F}[f(t)]=\int_{-\infty}^{\infty} f(t) e^{-2 \pi i v t} d t.
\end{equation}

\par Primeiro calculamos a transformada de Fourier $\hat{f}(v)$ do sinal, em seguida por $\sinc(\nu / a)$, onde

\begin{equation}
    \sinc x \equiv \frac{\sin (\pi x)}{\pi x},
\end{equation}

\par onde $a$ é um fator de escala. A função sinc foi escolhida para tirar vantagem do Teorema da Convolução, dado por

\begin{equation}
    \mathscr{F}^{-1}[\hat{f}(\nu) \hat{g}(\nu)]=(f * g)(t)=\int_{-\infty}^{\infty} f(\tau) g(t-\tau) d \tau, 
\end{equation}

\par onde $(f * g)(t)$ é a convolução entre $f(t)$ e $g(t)$. Multiplicar o sinal transformado por $\sinc (\nu / a)$ e depois inverter inverter a transformação é o mesmo que convoluir o sinal original com a transformação inversa de $\sinc (\nu / a)$, pois

\begin{equation}
\mathscr{F}^{-1}[\sinc(\nu)]=\rect(t) \equiv \begin{cases}1, & -\frac{1}{2}<t<\frac{1}{2} \\ 0, & \text { qualquer outro }t\end{cases},
\end{equation}

é uma função que representa uma janela retangular. Resultados desse procedimento estão na figura \ref{fig:bs_fourier_exs}.

\begin{figure}[H]
\centering
    \begin{subfigure}[c]{0.47\textwidth}
        % \centering
        \includegraphics[scale=0.49]{figs/bs_fourier_1.png}
        \caption{}
        \label{subfig:bs_fourier_1}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[c]{0.47\textwidth}
        % \centering
        \includegraphics[scale=0.49]{figs/bs_fourier_2.png}
        \caption{}
        \label{subfig:bs_fourier_2}
    \end{subfigure}
    \begin{subfigure}[b]{0.47\textwidth}
        \centering
        \includegraphics[scale=0.49]{figs/bs_fourier_3.png}
        \caption{}
        \label{subfig:bs_fourier_3}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.47\textwidth}
        \centering
        \includegraphics[scale=0.49]{figs/bs_fourier_4.png}
        \caption{}
        \label{subfig:bs_fourier_4}
    \end{subfigure}
\caption{Histogramas com as respectivas \textit{baselines} (linhas tracejadas) estimadas pelo método da convolução. O espectro resultante (sem o fundo) está em verde.}
\label{fig:bs_fourier_exs}
\end{figure}

\par Esse não é o melhor método pois, em muitos casos, acaba estimando o sinal original, na região do pulso, menor do que deveria ser, fazendo com que o sinal tenha menos carga do que deveria. Isso ocorre pois o sinal de fundo não é analítico, dificultando muito o problema.

\par Para um resultado mais eficiente, o fundo será determinado usando o algoritmo \textit{background removal} da biblioteca \textit{TSpectrum} do \textit{ROOT} \cite{root}. A função tem a capacidade de separar o fundo dos picos presentes no espectro\cite{BKG_1, BKG_2, BKG_3}. Exemplos de estimativa do fundo estão na figura \ref{fig:ex_sinal_bkg}.

\begin{figure}[H]
\centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/ex_sinal_bkg_1.png}
        \caption{}
        \label{subfig:ex_sinal_bkg_1}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/ex_sinal_bkg_2.png}
        \caption{}
        \label{subfig:ex_sinal_bkg_2}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/ex_sinal_bkg_3.png}
        \caption{}
        \label{subfig:ex_sinal_bkg_3}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/ex_sinal_bkg_4.png}
        \caption{}
        \label{subfig:ex_sinal_bkg_4}
    \end{subfigure}
\caption{Histogramas com as respectivas \textit{baselines} (linhas tracejadas) calculadas pelo \textit{TSpectrum}.}
\label{fig:ex_sinal_bkg}
\end{figure}

\par Para evitar valores negativos após a remoção do fundo, o valor mínimo do sinal sem o fundo é zero.

% \par Com o fundo podemos então subtraí-lo do espectro. Podem aparecer valores negativos após a retirada do fundo, então para evitar esse problema o valor mínimo do sinal, após a retirada do fundo, é zero.

\par Sem o fundo podemos buscar por todos os picos e suas cargas correspondentes no sinal. Não podemos detectar diretamente todos os picos pois muitos deles estão em sobreposição. Para isso será feita a deconvolução do sinal.

\subsection{Deconvolução do sinal}

Para aumentar a resolução dos picos será usado o algoritmo \textit{gold deconvolution} presente na biblioteca \textit{TSpectrum} do \textit{ROOT}\cite{paper_gold_deconv}. O algoritmo tem como objetivo fazer a deconvolução do espectro, gerando uma função resposta de acordo com o sigma esperado para os pulsos. Isso significa que devemos descobrir qual o valor de sigma dos pulsos para buscar a função resposta.

\par O sigma dos pulsos deve ser o mesmo de um sinal que possui apenas um pico. Ou seja, podemos determinar o sigma fazendo a análise de sinais que possuem apenas 1 pico, fazendo um ajuste pelo método dos mínimos quadrados (MMQ) de uma gaussiana. Para buscar espectros com apenas um pico foi usado o algoritmo de detecção de picos do \textit{scipy}\cite{scipy} e para o ajuste da gaussiana foi usada o pacote \textit{lmfit} \cite{lmfit}. O valor de sigma encotrado foi de 4.09 (17) \textit{time buckets}.

\par O sigma escolhido foi ligeiramente maior, pois em alguns casos a deconvolução separava um pico real em dois. O valor de sigma usado na deconvolução foi de 4.30 \textit{time buckets}. Devemos também escolher o número de iterações do algoritmo de deconvolução. O número de iterações escolhido foi de 700, menos que isso o algoritmo não estava separando totalmente picos sobrepostos. O limiar para a escolha de um ponto como um pico é ter altura maior que 20\% do valor máximo do sinal. Resultados da deconvolução estão na figura \ref{fig:ex_sinal_deconv}.

\begin{figure}[H]
\centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/ex_deconv_1.png}
        \caption{}
        \label{subfig:ex_sinal_deconv_1}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/ex_deconv_2.png}
        \caption{}
        \label{subfig:ex_sinal_deconv_2}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/ex_deconv_3.png}
        \caption{}
        \label{subfig:ex_sinal_deconv_3}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/ex_deconv_4.png}
        \caption{}
        \label{subfig:ex_sinal_deconv_4}
    \end{subfigure}
\caption{Histogramas sem as \textit{baselines} antes (em azul) e depois da deconvolução (em vermelho). Os picos (em verde) e o limiar (linha tracejada preta) de detecção também estão indicados.}
\label{fig:ex_sinal_deconv}
\end{figure}

\par O algoritmo de deconvolução também retorna a posição dos centroides encontrados. A execução de 200.000 sinais, desde a estimativa e remoção do fundo, até a detecção dos centroides, demora cerca de 23.25 minutos, usando o processador Ryzen 5 3600X.

\par Para determinar a carga de cada ponto temos que calcular a área do centroide do pico detectado. A área do sinal antes e depois da deconvolução é a mesma, mesmo para a região dos pulsos, portanto podemos olhar diretamente para o sinal após a deconvolução. Para achar a área podemos calcular o sigma dos pulsos após a deconvolução, para determinar a área como uma simples integral gaussiana. O sigma dos pulsos após a deconvolução é $\sigma_{dd}$ = 1.1543 (44) \textit{time buckets}. Com isso podemos calcular a carga acumulada para cada ponto descoberto do evento. A carga acumulada $Q$ para cada ponto $i$ é dada por:

\begin{equation}\label{eq:gauss_area}
    Q = \int^\infty _{-\infty} Ae^{-(t' - t_i)^2 / 2\sigma_{dd}^2} dt' = A\left |\sigma_{dd} \right|\sqrt{2\pi},
\end{equation}

\par onde $A$ é a amplitude do ponto com centroide $t_i$ e desvio padrão após a deconvolução $\sigma_{dd}$. Com esse procedimento podemos então reconstituir os eventos (nuvens de pontos), obtendo, para cada evento, todas as coordenadas $x$, $y$, $t$ e $Q$ de cada ponto. A figura \ref{fig:ex_eventos} mostra exemplos de eventos reconstruídos.

\begin{figure}[H]
\centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/ex_ev_1.png}
        \caption{}
        \label{subfig:ex_ev_1}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/ex_ev_2.png}
        \caption{}
        \label{subfig:ex_ev_2}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/ex_ev_3.png}
        \caption{}
        \label{subfig:ex_ev_3}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/ex_ev_4.png}
        \caption{}
        \label{subfig:ex_ev_4}
    \end{subfigure}
\caption{Exemplos de eventos reconstruídos através da análise dos sinais. A seta vermelha indica o sentido do feixe.}
\label{fig:ex_eventos}
\end{figure}

\section{Análise dos pulsos com \textit{machine learning}}

% \par Da mesma forma que na seção anterior, queremos fazer a reconstrução dos eventos a partir dos histogramas gerados pelos canais do detector. O que precisamos é da posição dos centroides presentes no espectro, porém não é tarefa que pode ser resolvida diretamente, é necessário quebrar em etapas, ou seja, deve-se remover o sinal de fundo, fazer a deconvolução do espectro (já sabendo qual o valor de sigma) para enfim buscar os picos.

% \par Com \textit{machine learning} temos a possibilidade de criar algoritmos extremamente complexos sem definir operações explícitas como na seção anterior. Da solução anterior, para um vetor de tamanho $n$, a complexidade do consumo de tempo é $\mathcal{O}$($n$) para determinar o fundo, $\mathcal{O}$($m\times n$) para $m$ iterações da deconvolução e $\mathcal{O}$($n$) para detecção de picos. Sendo o maior consumo de tempo a deconvolução, podemos construir uma rede neural que faça a deconvolução porém em menor tempo. Devido à eletrônica do detector, o fundo do sinal de cada espectro possui informações relevantes para entender o funcionamento de cada pixel do detector, sua estimativa é importante para determinação de incertezas. Somado ao fato que para fazer a deconvolução é preciso do sinal sem a \textit{baseline}, então a estratégia será criar uma rede neural para nos dar a \textit{baseline} do espectro e uma que faça a deconvolução.

\par Com \textit{machine learning} temos a possibilidade de criar algoritmos extremamente complexos sem definir operações explícitas. Podemos nos basear na metodologia da seção anterior que é dividir o problema em três etapas: remover o fundo, fazer a deconvolução e por fim detectar os picos. A subseções seguintes irão descrever uma rede neural para cada etapa.

\subsection{Rede neural para o fundo}

\par O objetivo é criar uma rede neural que reproduza o comportamento do algoritmo \textit{background removal} que estima o fundo do sinal, tentando reproduzir resultados muito similares. A rede neural neural é supervisionada, onde os dados de entrada são os sinais brutos e as saídas devem ser os fundos de cada sinal. A arquitetura está na figura \ref{fig:arq_source_to_bkg}.

% \par Estimar o fundo é uma tarefa muito complexa pois a eletrônica do detector faz com que o sinal do canal varie muito dependendo do evento, podendo muitas vezes fazer com que o fundo tenha saltos no espectro após receber o sinal de um pulso. Importante ressaltar que a retirada do fundo não precisa ser considerada perfeita. O próprio algoritmo analítico de remoção de fundo não é perfeito e no geral nunca coloca toda a parte que não é o pulso em 0, há muitas flutuações. O importante é tentar deixar o mais próximo de zero possível. 

\par Estimar o fundo é uma tarefa muito complexa pois ele não é analítico, podendo muitas vezes fazer com que o fundo tenha saltos em diferentes \textit{time buckets}. 

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.28]{figs/Source to only bkg.png}
    \caption{Arquitetura da rede neural que faz a inferência do fundo. O vetor de entrada deve ter dimensionalidade 512 x 1. Todas as partes com convolução não possuem o parâmetro \textit{bias}.}
    \label{fig:arq_source_to_bkg}
\end{figure}

\par A entrada da rede é o sinal com dimensionalidade 521 x 1. Há duas convoluções seguidas (passagens \textit{a} e \textit{b}) com o \textit{padding same}, seguida de um \textit{Max pooling}. Os dois canais restantes sofrem um \textit{flat} para então passar mais uma convolução com \textit{padding same} e filtros de tamanho 19 seguido de \textit{Max pooling} e \textit{Fully Connected} com ativação \textit{ReLU}. Toda a rede foi construída usando o TensorFlow 2 e possui um total de 545.536 parâmetros, todos treináveis. O tamanho dos filtros das convoluções devem levar em conta a largura do pulso, devendo ser no mínimo maior que a largura, a fim de cada \textit{kernel} visualizar um pulso completo na convolução.

\par A camada final com ativação \textit{ReLU} garante o valor mínimo de saída em 0 e, principalmente, pelo fato de não causar problemas à minimização do gradiente \cite{VGP}. Foram testadas diversas combinações e a mostrada na figura \ref{fig:arq_source_to_bkg} é a que obteve os melhores resultados. 
% Caso, por exemplo, na passagem \textit{c} da figura, o \textit{pool size} da camada de \textit{max pooling} fosse 32 (a fim de sobrarem 512 canais igual na entrada e na saída), a rede parece não entender as oscilações grandes do sinal de fundo.

\par Para o treino foram usados 160.000 sinais para treino e 40.000 para validação. O \textit{loss} foi escolhido como sendo o erro quadrático médio (equação \ref{eq:erro_abs_m}, o otimizador foi o \textit{ADAMAX} \cite{ADAMAX}, com \textit{learning rate} de 0.0005, e métrica para avaliação foi o erro médio absoluto, dado por. 

\begin{equation}\label{eq:erro_abs_m}
    E = \frac{1}{N}\sum_{i = 1}^{N} \left | x_i - \Hat{x}_i\right |,
\end{equation}

onde $E$ é o erro absoluto médio, $N$ é o número de pontos e $x_i$ o ponto da saída da rede para ser comparado com o ponto original $\Hat{x}_i$. Foram 30 \textit{epochs} e o \textit{batch-size} foi 8. O treino foi realizado no Google Colaboratory \cite{google_colab} usando a GPU (graphics processing unit) NVIDIA Tesla P100 e durou cerca de 34 minutos. Os resultados do treino estão na figura \ref{fig:source_to_bkg_results}.

% \par Como dito na seção \ref{sec:ml} temos que especificar qual o tamanho do filtro das camadas convolucionais. Para determinar o fundo precisamos, ponto a ponto, determinar quantos canais na direita e na esquerda o filtro deve atuar. Por exemplo, caso o tamanho do filtro fosse 3, ele só estaria ``enxergando" um ponto à direita e um à esquerda, para então passar a informação a diante, porém claramente é um filtro muito pequeno, as oscilações podem variar mais do que 5 canais. Além disso, quando há o começo de um pulso no sinal, ele pode se estender por múltiplos canais, então é preciso escolher um tamanho de filtro grande o suficiente para enxergar todas essas diferenças. A rede consta com duas camadas convolucionais em sequência com filtros de tamanho 21 e 19, respectivamente.

\begin{figure}[H]
\centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/source_to_bkg_loss.png}
        \caption{\textit{Loss} dos dados de treino (linha contínua) e dos dados de validação (linha tracejada) em função da \textit{epoch} no treino da rede dada por \ref{fig:arq_source_to_bkg}.}
        \label{subfig:source_to_bkg_loss}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/source_to_bkg_metric.png}
        \caption{Erro absoluto médio dos dados de treino (linha contínua) e dos dados de validação (linha tracejada) em função da \textit{epoch} no treino da rede dada por \ref{fig:arq_source_to_bkg}.}
        \label{subfig:source_to_bkg_metric}
    \end{subfigure}
\caption{Resultados do treino da rede neural dada por \ref{fig:arq_source_to_bkg}. A rede atingiu seu melhor resultado a partir da \textit{epoch} 20 aproximadamente, quando começa um 
platô no \textit{loss}.}
\label{fig:source_to_bkg_results}
\end{figure}

% \par A métrica do erro absoluto médio mede ponto a ponto qual o erro absoluto da previsão. 

\par Exemplos de resultados da rede podem ser vistos na figura \ref{fig:stb_examples}. A previsão do fundo possui um erro absoluto nos dados de treino de 6.5315 Channels e nos dados de validação de 6.0783 Channels. Podemos subtrair o fundo do sinal original (colocando o valor minimo da subtração em 0). Comparando o erro médio absoluto de 200.000 sinais sem o respectivo fundo (resultante do algoritmo do TSpectrum) com o resultado da rede neural obtemos 4.5 Channels.
% Esse erro significa que, por exemplo, para o menor pico detectado considerado, que possui amplitude de cerca de 60 unidades em y, a incerteza estimada da amplitude seria de 7.5\%, ou seja, na menor amplitude possível para um pico a incerteza propagada seria de 7.5\% da amplitude.

\par Rede neurais convolucionais têm a vantagem de usarem poucas variáveis e serem facilmente paralelizadas em sua execução. Uma vantagem de redes neurais é o seu tempo de execução. Empiricamente a rede neural pode executar 200.000 sinais em apenas 8s (ou 25.000 sinais por segundo), sendo extremamente eficiente em tempo.

\begin{figure}[H]
\centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.445]{figs/stb_1.png}
        \caption{}
        \label{subfig:stb_ex1}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.445]{figs/stb_2.png}
        \caption{}
        \label{subfig:stb_ex2}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.445]{figs/stb_3.png}
        \caption{}
        \label{subfig:stb_ex3}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.445]{figs/stb_4.png}
        \caption{}
        \label{subfig:stb_ex4}
    \end{subfigure}
\caption{Exemplos da rede neural dada por \ref{fig:arq_source_to_bkg} em comparação com a saída do \textit{TSpectrum}.}
\label{fig:stb_examples}
\end{figure}

\par Nos exemplos mostrados nas figuras \ref{subfig:stb_ex1}, \ref{subfig:stb_ex2} e \ref{subfig:stb_ex1} os fundos dos sinais possuem grande flutuação e a rede neural se mostrou eficaz na previsão. No exemplo \ref{subfig:stb_ex4} a \textit{baseline} do sinal é extremamente complexo de se determinar pois o sinal, do canal 300 a 500 aproximadamente, varia em cerca de 50 unidades em \textit{y}. Apesar da rede neural determinar o fundo acima do fundo original, ao subtrair o espectro do fundo e colocar o valor mínimo em 0, o pulso presente entre os canais 200 e 300 é praticamente inalterado.

\par Com os resultados da rede podemos então seguir a diante para criar a rede neural que faz a deconvolução do espectro sem a \textit{baseline}.

\subsection{Rede neural para a deconvolução}

% \par O próximo passo é construir uma rede neural que dê a posição dos picos. A tarefa a princípio não parece complicada. Pensando de forma simples, podemos fazer uma arquitetura curta e, como precisamos de uma saída de tamanho fixo, classificamos ponto a ponto como sendo não pico ou pico.

% \par O problema nessa abordagem é o desbalanço de classe evidente nos sinais. Caso tenhamos que classificar ponto a ponto em que, por exemplo, 0 representa um ponto que não é o centroide e 1 como um ponto que é um centroide, colocando na ultima camada a função de ativação \textit{sigmoid} (para sair valores entre 0 e 1), há muito mais valores 0 que 1. Se, por exemplo, temos um sinal que possui apenas um pico, teríamos que acertar o único valor 1 dentre 511 zeros. Caso a rede assuma que são 512 zeros, ainda assim a acurácia binária seria de mais de 99\%.

% \par Outro problema é que há um \textit{overlap} de gaussianas. Não é tão evidente a posição dos centroides se o espectro não está deconvoluído. É muito mais complicado, mesmo olhando, dizer a posição. Portanto o problema será quebrado em mais uma etapa: construir um rede que faça a deconvolução.

\par Podemos usar a mesma abordagem da rede neural anterior, fazer uma sequencia de convoluções e por fim uma \textit{fully connected} com ativação \textit{ReLU}, pois precisamos ter o valor mínimo do espectro em 0. Os filtros das convoluções precisam ter tamanho mínimo de duas vezes o sigma das gaussianas para atuarem sobre cada pulso do espectro. A entrada da rede é o sinal com o fundo subtraído e com mínimo em 0. A saída é a deconvolução dada pelo algoritmo \textit{gold deconvolution} na biblioteca \textit{TSpectrum} do ROOT. A figura \ref{fig:source_to_deconv} mostra a arquitetura da rede de deconvolução.

\par A rede é a sequência de duas convoluções com 32 filtros, \textit{valid padding} e \textit{kernels} de tamanho 19 e 17, respectivamente, seguida de \textit{Max pooling} com \textit{pool size} igual à 16. No final há o \textit{flat} na camada para seguir com uma \textit{fully connected} com ativação \textit{ReLU}. O \textit{valid padding} se mostrou mais eficiente para a convergência da rede. Toda a rede foi construída usando o TensorFlow 2, possuindo 508.000 parâmetros treináveis.

\par Assim como na rede anterior, foram usados 160.000 sinais para treino e 40.000 para validação. O \textit{loss} foi escolhido como sendo o erro quadrático médio, o otimizador foi o \textit{ADAM}, com \textit{learning rate} de 0.0005 porém com o parâmetro \textit{clipnorm} igual a 0.45. A métrica para avaliação foi o erro médio absoluto. Foram 75 \textit{epochs} e o \textit{batch-size} foi 8. Os resultados do treino estão na figura \ref{fig:source_wo_bkg_to_deconv_results}.

\par Alterar a norma do gradiente (usar o parâmetro \textit{clipnorm} = 0.45) significa que, caso a norma do vetor do gradiente exceda 0.45, então o valor da norma é reajustado para o \textit{threshold} escolhido (0.45). Isso faz com que não ocorra problemas comuns como o gradiente sumir\cite{VGP, ADAMAX}, o que estava acontecendo especificamente nesse caso.

\par O treino foi realizado no Google Colaboratory \cite{google_colab} usando a GPU NVIDIA Tesla P100 e demorou cerca de 54 minutos. Os resultados do treino estão na figura \ref{fig:source_to_bkg_results}. Empiricamente a rede é capaz de executar 200.000 sinais em 5.4 segundos (ou 37.000 sinais por segundo).

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.28]{figs/source_wobkg_to_deconv.png}
    \caption{Arquitetura da rede neural que faz a inferência da deconvolução do espectro. O vetor de entrada deve ter dimensionalidade 512 x 1. Todas as partes com convolução não possuem o parâmetro \textit{bias}.}
    \label{fig:source_to_deconv}
\end{figure}

\begin{figure}[H]
\centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.44]{figs/source_wo_bkg_to_deconv_loss.png}
        \caption{\textit{Loss} dos dados de treino (linha contínua) e dos dados de validação (linha tracejada) em função da \textit{epoch} no treino da rede dada por \ref{fig:source_to_deconv}.}
        \label{subfig:source_wo_bkg_to_deconv_loss}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/source_wo_bkg_to_deconv_metric.png}
        \caption{Erro absoluto médio dos dados de treino (linha contínua) e dos dados de validação (linha tracejada) em função da \textit{epoch} no treino da rede dada por \ref{fig:source_to_deconv}.}
        \label{subfig:source_wo_bkg_to_deconv_metric}
    \end{subfigure}
\caption{Resultados do treino da rede neural dada por \ref{fig:arq_source_to_bkg}.}
\label{fig:source_wo_bkg_to_deconv_results}
\end{figure}

% \par A mudança em relação à rede que faz a inferência do sinal de fundo é que o \textit{padding} das camadas agora é \textit{valid}. Agora não estamos verificando pontos onde seriam necessários adicionar zeros além do vetor de entrada, como explicado na seção \ref{sec:ml}. O \textit{padding} \textit{valid} se mostrou mais eficiente com relação à separação das gaussianas, dando melhor resolução para buscar os centroides. Além disso, ao colocar o \textit{pool size} de apenas 16, para poder dar um \textit{flat} na camada seguinte, fez com que a resolução de separação das gaussianas fosse inclusive melhor que a do algoritmo analítico. A figura \ref{fig:std_examples} mostra um exemplo da saída da rede.

\begin{figure}[H]
\centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.445]{figs/swbtd_1.png}
        \caption{}
        \label{subfig:std_ex1}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.445]{figs/swbtd_2.png}
        \caption{}
        \label{subfig:std_ex2}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.445]{figs/swbtd_3.png}
        \caption{}
        \label{subfig:std_ex3}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.445]{figs/swbtd_4.png}
        \caption{}
        \label{subfig:std_ex4}
    \end{subfigure}
\caption{Exemplos de deconvolução da rede neural dada por \ref{fig:arq_source_to_bkg}.}
\label{fig:std_examples}
\end{figure}


\subsection{Unificando as duas redes neurais}

\par Com a rede que prevê o fundo e a que faz a deconvolução funcionando podemos agora testar se acopladas elas geram resultados satisfatórios, verificando a qualidade da detecção de picos. Usando novamente o TensorFlow 2 podemos carregar as redes neurais já treinadas e usar como se fosse uma única rede neural. A rede receberá de entrada o espectro original e devolverá tanto o fundo quanto o espectro deconvoluído. A arquitetura da rede está na figura \ref{fig:arq:source_to_deconv}.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.28]{figs/source_to_deconv.png}
    \caption{Arquitetura da rede neural que faz a inferência da \textit{baseline} e depois faz a deconvolução do espectro. O vetor de entrada deve ter dimensionalidade 512 x 1.}
    \label{fig:arq:source_to_deconv}
\end{figure}

\par A rede é apenas a sequencia das redes anteriores, ou seja, o espectro passa pelo cálculo da \textit{baseline}, então o espectro original é subtraído dessa \textit{baseline} (colocando o valor mínimo em 0) e por fim ocorre a deconvolução. Pelo fato de cada parte ser treinada de modo separado não há necessidade de treinar a rede unificada, apenas carregar os valores das variáveis treinadas de cada parte. A rede unificada possui 1.053.536 de parâmetros.

\par Agora devemos comparar a saída dessa nova rede com a saída desejada. Podemos usar novamente o erro médio absoluto para fins de comparação. O erro médio absoluto, para os 200.000 sinais, é de 7.45 ADC. O valor é um pouco maior que o encontrado anteriormente com a rede de deconvolução, portanto podemos verificar a detecção de picos no espectro resultante.

\par Com o espectro deconvoluído devemos então detectar todos os picos em cada sinal. A detecção será feita com o \textit{SciPy} que possui rotinas para a detecção. A função que usada é a ``find\_peaks", onde é possível determinar altura mínima de detecção, distância mínima entre picos, dentre outros parâmetros, o que torna possível calibrar a detecção para o caso discutido. O objetivo será fazer a comparação entre os picos resultantes do algoritmo de deconvolução (na biblioteca \textit{TSpectrum} do ROOT) e os resultantes do algoritmo do \textit{SciPy}.

\par A comparação se limitou a detecção de 0 a 6 picos detectados pela deconvolução, que é o intervalo que faz sentido físico (mais que 6 picos detectados indica um sinal muito ruidoso). Caso o \textit{SciPy} detecte mais que 6, então o espectro é descartado. Primeiro deve-se ver a comparação do número de espectros detectado por evento de cada algoritmo. O histograma da figura \ref{fig:hist_2d_peaks} mostra essa comparação.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.48]{figs/hitograma_2d_peaks.png}
    \caption{Histograma bidimensional que mostra em $x$ a contagem do número de picos detectados por sinal (dado pelo \textit{TSpectrum}) pela deconvolução e em $y$ a contagem do número de picos detectados por sinal (resultante da rede neural) pelo \textit{scipy}. O número de contagens está marcado em cima de cada \textit{bin}.}
    \label{fig:hist_2d_peaks}
\end{figure}

\par A linha tracejada serve de referência para os caso em que o número de picos detectador por ambos algoritmos foi igual. A dispersão de detecção se dá em torno dessa e se mostrou com uma diferença muita baixa, indicando que o processamento de sinal pela rede neural seguido pela detecção de picos com o \textit{scipy} é equivalente ao dado pelo uso dos algoritmos do \textit{TSpectrum}. Para os casos em que o número detectado de picos foi o mesmo, a diferença da posição dos centroide é de 0.11 canais, mostrando que os métodos são praticamente equivalentes.
%  O valor não é a soma direta dos tempos das redes anteriores pois em Python existe a questão da vetorização de operações
\par Com relação a eficiência, a rede neural da figura \ref{fig:arq:source_to_deconv} processa 200.000 sinais em 8 segundos. Agora levando em conta a detecção de picos com o \textit{SciPy}, o tempo total para processar 200 mil sinais é de cerca de 25 s. Nem foi preciso uma rede neural para os picos e a eficiência em tempo já é 30 vezes maior em comparação ao método analítico.

\par Exemplos da reconstrução das nuvens de pontos usando \textit{machine learning} com detecção de picos pelo \textit{SciPy} estão na figura \ref{fig:ml_pc_exs}. É possível perceber uma pequena melhora no ruído dos eventos, pois o com o \textit{SciPy} podemos calibrar melhor a detecção. Além disso há uma correlação de amplitude do pico detectado entre espectro sem o fundo e o espectro sem o fundo após a deconvolução, como mostrado na figura \ref{fig:corr_amps}. Colocando a condição de que, para cada pico detectado, a razão entre a amplitude do espectro após a deconvolução e do espectro original para o ponto seja maior que 3.8 faz com que a quantidade de pontos por evento caia em cerca de 35\% em relação ao método analítico.

\begin{figure}[H]
\centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/ml_pc_ex1.png}
        \caption{}
        \label{subfig:ml_pc_ex1}
    \end{subfigure}%
    \vspace{0.2cm}
    % \hfill
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/ml_pc_ex2.png}
        \caption{}
        \label{subfig:ml_pc_ex2}
    \end{subfigure}
\caption{Resultados da reconstrução de eventos por \textit{machine learning}.}
\label{fig:ml_pc_exs}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.85]{figs/corr_pulso_deconv.png}
    \caption{Histograma bidimensional que mostra a relação, de cada pico detectado, entre a amplitude do pico após a deconvolução no eixo $y$ e antes da deconvolução no eixo $x$. A linha tracejada indica a tendência da maior parte dos pontos. Já a linha sólida indica a região de corte dos pontos.}
    \label{fig:corr_amps}
\end{figure}

% \subsection{}


% \par Podemos usar o \textit{TensorFlow} que possui diversas ferramentas para construir a arquitetura de modo à simplesmente fazer a conta sequencialmente, ou seja, calcular o fundo, subtrair o fundo do espectro original e fazer para a deconvolução. Os valores de cada variável de cada arquitetura está salvo e basta carregar cada rede feita individualmente e colocar os pesos (valores) nas camadas corretas. A arquitetura unificada está mostrada na figura [xx].

% \par O consumo de tempo para a análise usando o \textit{TSpectrum} é de cerca de 10 minutos para 200 mil sinais. Boa parte desse tempo se dá pela deconvolução, que é um algoritmo que cresce quanto mais iterações são necessárias (foram usadas 300 iterações). A remoção do fundo e a detecção de picos são algoritmos muito mais rápidos, portanto só a deconvolução por redes neurais já pode economizar mais de 90\% do tempo. A rede processa 200 mil arrays em apenas 11 segundos. Podemos usar na sequencia um algoritmo de detecção de picos simples como o presente na biblioteca do \textit{scipy}. O tempo de execução desses arrays mais a detecção de picos (ou seja, a rede neural remove o fundo e faz a deconvolução, enquanto a detecção de picos é por algoritmos analíticos) é de apenas 24 segundos, mesmo sendo executado em \textit{Python}. O uso de redes neurais facilita muito a análise de quantidades massivas de dados, podendo inclusive permitir a análise em tempo real de um experimento.

\subsection{Detecção de picos}

\par Como etapa final da análise com \textit{machine learning} devemos analisar possíveis soluções para a detecção de picos. Esse é um problema extremamente complicado, pois há uma variação na quantidade de detecções muito grande e há um desbalanço muito grande na quantidade de pontos comuns (não sendo picos) e pontos que são picos. Por exemplo, caso haja um sinal que possui apenas um pico, devemos detectar uma posição, dar o valor de saída como 1, por exemplo, dentre 512 pontos, onde 511 terão o valor de saída como 0. Caso a rede determine que todos os pontos são não picos, ainda assim a acurácia seria maior que 99\%.

\par Para resolver esse problema podemos nos basear na ideia de recortar regiões de interesse, como feito pela rede U-Net\cite{unet}. Recortar regiões significa, nesse caso, ter uma rede neural com a saída com o mesmo tamanho do vetor de entrada (512) e saída com valores entre 0 e 1, onde 1 indica uma região com um pico e 0 não. Como temos as posições dos picos, basta acrescentar pontos simetricamente em torno do pulso. A figura \ref{fig:n_peaks_exs} mostra um exemplo de um sinal após a deconvolução onde há o pico detectado e os pontos acrescentados para representar a região do pulso.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.54]{figs/np_ex1.png}
    \caption{Sinal após a deconvolução que mostra o pico detectado mais os pontos adicionais que irão facilitar o trabalho da rede neural (evitar o desbalanço de classe). Foram acrescentados 2 pontos à esquerda e à direita.}
    \label{fig:n_peaks_exs}
\end{figure}

\par A rede construída é é uma convolução com \textit{kernel} de tamanho 13 e \textit{same padding} seguida de \textit{Max-Pooling} e uma \textit{fully-connected} com ativação sigmoide, possuindo um total de 263.104 parâmetros treináveis. Foram usados sinais que possuíam entre 1 e 6 picos, resultantes da saída do \textit{SciPy}, o que resultou em 120.024 de dados para o treino e 30.006 para validação. A escolha pelos picos detectados pelo \textit{SciPy} ao invés do TSpectrum é pela maior facilidade de fazer um ajuste fino na detecção, tornando a detecção de picos muito melhor. O \textit{loss} escolhido foi a \textit{binary cross-entropy}, o otimizador o \textit{ADAM} com \textit{learning rate} de 0.001. A métrica utilizada foi a acurácia binária. O treino também foi realizado por uma GPU NVIDIA Tesla P100 e durou cerca de 8 minutos com 12 \textit{epochs}. A arquitetura da rede está na figura \ref{fig:arq:n_peaks} e os resultados do treino estão na figura \ref{fig:n_peaks_results}.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.35]{figs/n_peaks.png}
    \caption{Arquitetura da rede neural que faz o recorte das regiões com picos. O vetor de entrada deve ter dimensionalidade 512 x 1.}
    \label{fig:arq:n_peaks}
\end{figure}

\begin{figure}[H]
\centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.44]{figs/n_peaks_loss.png}
        \caption{\textit{Loss} dos dados de treino (linha contínua) e dos dados de validação (linha tracejada) em função da \textit{epoch}.}
        \label{subfig:n_peaks_loss}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.45]{figs/n_peaks_metric.png}
        \caption{Acurácia binária dos dados de treino (linha contínua) e dos dados de validação (linha tracejada) em função da \textit{epoch}.}
        \label{subfig:n_peaks_metric}
    \end{subfigure}
\caption{Resultados do treino da rede neural dada por \ref{fig:arq:n_peaks}.}
\label{fig:n_peaks_results}
\end{figure}

\par A saída da rede neural é um vetor de tamanho 512 com valores entre 0 e 1. Exemplos da saída da rede estão na figura [xx]. Para obter os picos a partir desse vetor devemos, primeiro, identificar a segmentação feita, ou seja, saber separar as regiões recortadas e depois fazer uma média ponderada com o espectro de entrada (para achar o centroide). O tempo de processamento da rede neural é de 150.030 sinais em cerca de 4.11 segundos (aproximadamente 36.500 sinais por segundo). Para determinar os picos a partir da saída da rede o tempo é de aproximadamente 4.3 segundos, onde o algoritmo pode ser ainda mais rápido se for paralelizado.

\chapter{Análise das nuvens de pontos}

\par Após a análise dos espectros, temos agora que trabalhar na etapa de detecção e reconstrução de trajetórias. O objetivo desta etapa é detectar \textit{clusters}, que nesse caso são retas tridimensionais (o pAT-TPC só possui campo elétrico), distinguir cada reta como sendo ou o feixe ou a partícula espalhada e determinar o vértice de reação entre uma reta, que é de uma partícula espalhada, e o feixe (se houver). Após a seleção devemos selecionar os eventos que possuam espalhamento. Um exemplo de evento pode ser visto na figura \ref{subfig:exemplo_1}.

\begin{figure}[H]
\centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[scale = 0.45]{figs/Figure_1.png}
        \caption{Exemplo de evento a ser analisado. Os pontos em azul são das partículas detectadas pelo TPC, a seta vermelha indicando o sentido do feixe e o TPC está representado pelo cilindro cinza.}
        \label{subfig:exemplo_1}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[scale=0.25, width=.95\columnwidth]{figs/Figure_8.png}
        \caption{Evento sem a clusterização. As retas de cor amarela e verde são de um único \textit{cluster}.}
        \label{subfig:antes_clustering}
    \end{subfigure}%
    \hspace{0.5cm}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[scale=0.25, width=.95\columnwidth]{figs/fig_cluster.png}
        \caption{Evento após a clusterização. Agora o evento possui as duas retas corretas, a azul e a verde.}
        \label{subfig:depois_clustering}
    \end{subfigure}
\caption{Sequência de análise de um evento. Em \ref{subfig:exemplo_1} temos o evento que é recebido para ser analisado, em \ref{subfig:antes_clustering} temos o mesmo evento após o RANSAC (antes da clusterização) e \ref{subfig:depois_clustering} mostra depois da correção. As cores das retas são arbitrárias e servem apenas para a diferenciação.}
\label{fig:3d_examples}
\end{figure}


% \begin{figure}[H]
%     \centering
%     \includegraphics[scale = 0.6]{figs/Figure_1.png}
%     \caption{Exemplo de evento a ser analisado. Os pontos em azul são das partículas detectadas pelo TPC, a seta vermelha indicando o sentido do feixe e o TPC está representado pelo cilindro cinza.}
%     \label{fig:exemplo_1}
% \end{figure}
% \newpage
\par A etapa anterior nos fornece arquivos no formato \textit{ROOT} para cada \textit{run} do experimento. O arquivo é dividido por eventos em que estão contidas informações, em \textit{trees}, como coordenadas x, y, z, t, carga, tempo de voo, além de canais adicionais (indicadores de partículas presentes além da parte central do \textit{micromegas}). Os arquivos foram lidos em Python usando a biblioteca Uproot\cite{uproot}.

\par A figura \ref{subfig:exemplo_1} nos mostra um exemplo que parece indicar mais de uma trajetória dentro do TPC, e é preciso separar os pontos de cada trajetória identificada. O objetivo é separar os pontos de \textit{clusters} que contenham a informação do momento da partícula, obtida a partir das propriedades geométricas do versor das retas e da energia inicial da trajetória. A identificação pode ser feita sem o uso de algoritmos de machine learning, que chamarei de método usual, e usando machine learning.

\section{Método usual}\label{sec:forcabruta}

\par Para identificar as retas (\textit{clusters}) presentes em eventos como mostrados na figura \ref{subfig:exemplo_1}, devemos usar estimadores robustos que consigam fazer a detecção mesmo com uma presença grande de \textit{outliers}, pontos que são considerados ruídos. Existem muitos estimadores, que são apenas variações do  Random sample consensus (\textit{RANSAC}) \cite{ransac}, como o MLESAC\cite{ref:MLESAC}, \textit{RRANSAC}, \textit{PROSAC}, dentre outros, que estão presentes no \textit{Point Cloud Library} (PCL)\cite{pcl}. Todos esses se baseiam na ideia de estimar várias possíveis retas de forma aleatória e selecionam a melhor usando uma estimativa (por isso o nome \textit{consensus}). Existe ainda a opção do \textit{Hough Transform}\cite{hough}, porém é um algoritmo de difícil expansão e não demonstrou resultados bons.


\par Os algoritmos do PCL foram testados e os que mostraram os melhores resultados foram o \textit{RANSAC} e o \textit{PROSAC}, não havendo muita diferença dentre os dois. O estimador usado foi uma variação do \textit{RANSAC}, desenvolvida para fazer melhores estimativas em dados como os do pAT-TPC\cite{artigo}. O algoritmo \ref{ransac_algo}, que chamei de \textit{Enhanced RANSAC} (Para você Juan: só quis diferenciar o nome, até pq eu quero colocar no pypi com esse nome, pode ser?), mostra o seu funcionamento. A melhor estimativa original (que retorna a melhor reta) era simplesmente o número total de \textit{inliers} de um \textit{cluster}. A nova estimativa \textit{C} passou a ser

\begin{equation} \label{criterio_ransac}
    C = \sum_{i = 0}^{N} \frac{d_i ^2}{N},
\end{equation}

onde \textit{N} é o número total de pontos de uma reta e $d_i$ é a distância do i-ésimo ponto à reta.

\begin{algorithm}
    \caption{Enhanced RANSAC}\label{ransac_algo}
    \KwData{pointcloud, $N$, $d_{min}$, $tam_{min}$}
    \For{cada iteração $ i =1,2,\ldots, N$}{
        Seleciona dois pontos da \textit{pointcloud} de modo aleatório (\textit{Random Sampling})\;
        Estima versor $v$ e um ponto $P_b$ que passe pela reta \textit{r} formada pelos dois pontos\;
        \For{cada ponto $P$}{
            Calcula a distância $d$ do ponto à reta \textit{r}\;
            \If{$d < d_{min}$}{
			    Guarda $P$ como pertencente à $r$\;
	        }
	    }
	    \If{Número de pontos de $r > tam_{min}$}{
	        Guarda $v$, $P_b$ e $C$\;
	    }
    }
    Ordena as retas do menor para o maior $C$\;
    \For{cada reta $r$ ordenada}{
        \If{Número de pontos de $r > tam_{min}$}{
            Guarda $v$, $P_b$ e pontos $P$ $\in r$\;
        }
    }
    \Return Retas $r$ selecionadas na última etapa\;
\end{algorithm}

\par O \textit{RANSAC} consegue identificar apenas pontos de uma única reta, porém cada evento pode ter mais de uma reta. O novo algoritmo se baseia na ideia de usar o RANSAC sequencialmente, ou seja, no momento que um \textit{cluster} tem um tamanho mínimo, então ele é guardado para depois, então, poder ser escolhidos dentre as melhores estimativas \textit{C}. Com isso podemos selecionar quantas retas forem possíveis.

\par Para diminuir o número de pontos a serem analisados pelo algoritmo \ref{ransac_algo}, passamos a \textit{pointcloud} por dois filtros. O primeiro filtro exclui pontos baseado na sua carga. O segundo filtro, chamado de \textit{outlier removal}, elimina pontos considerados \textit{outliers} globais, analisando a vizinhança ao redor do ponto. O \textit{outlier removal} está presente na biblioteca Open3D\cite{open3d} no Python e funciona excluindo pontos muito isolados uns dos outros.

\par Uma mudança na eficiência do algoritmo \ref{ransac_algo} é na linha 2, chamada de \textit{Random Sampling}. Podemos nos beneficiar do \textit{Monte Carlo Rejecting} na escolha de dois pontos aleatórios. Por exemplo, caso sejam selecionados pontos muito próximos, o que implicaria em uma reta com poucos pontos, podemos descarta-los. Essa ideia faz com que a primeira etapa seja mais eficiente.

\par O algoritmo \ref{ransac_algo} possui uma eficiência muito alta, acertando quais os \textit{clusters} que existem em um evento, porém ainda assim não é perfeito. Uma das falhas do algoritmo é que ele pode selecionar retas muito próximas e entender que não são um único \textit{cluster}, e sim dois distintos. A figura \ref{subfig:antes_clustering} mostra um exemplo em que foram detectadas três retas, onde deveria existir apenas duas (é necessário combinar duas delas).

\par A etapa de correção da saída do \textit{Enhanced Ransac} é chamada de clusterização. A ideia é comparar, dois a dois, todos os \textit{clusters} resultantes da saída e usar algum critério para juntar ou não os dois clusters. O problema precisa abordado avaliando a semelhança entre dois \textit{clusters}. Uma métrica possível é o coeficiente de silhueta \cite{silhueta}.

\par O coeficiente de silhueta compara dois \textit{clusters} e retorna um valor entre -1 e 1 que informa se estão separados corretamente. O valor -1 informa que a separação dos \textit{clusters} estão errados, 0 indica sobreposição e 1 significa que a separação está correta. A métrica se mostra muito viável para análise de duas dimensões, porém para o caso de três dimensões essa métrica não se mostrou muito eficiente. Mesmo colocando um \textit{threshold} muito baixo o algoritmo indicava que deveria juntar \textit{clusters} mesmo que muito distantes um do outro.

\par A abordagem correta se dá primeiro comparando o ângulo entre as duas retas. Caso a diferença absoluta entre os ângulos com relação ao versor (0, 0, 1) seja menor que um valor dado, que nesse caso foi considerado 9° (determinado empiricamente), então as duas retas serão combinadas se obedecerem a condição dada pela equação \ref{criterio_clustering}.

\begin{equation}\label{criterio_clustering}
    \sum_{i = 0}^{N_1}\frac{d_{i2}}{N_1} < \alpha \space d_{min}, 
\end{equation}

onde $N_1$ é o número de pontos da reta 1, $d_{i2}$ a distância do ponto $i$ da reta 1 em relação à reta 2, $\alpha$ é um parâmetro com valor a ser escolhido e $d_{min}$ é a distância mínima de ponto a reta usada no algoritmo \ref{ransac_algo}. Os valores escolhidos foram tais que $\alpha$ = 1.75 e $d_{min}$ = 15 mm. A figura \ref{subfig:depois_clustering} mostra o antes e depois da clusterização ser aplicada em um evento.


% \begin{figure}[H]
% \centering
%     \begin{subfigure}[b]{\textwidth}
%         \centering
%         \includegraphics[scale=0.85]{figs/Figure_8.png}
%         \caption{Evento sem a clusterização. As retas de cor azul e verde são de um único \textit{cluster}.}
%         \label{subfig:antes_clustering}
%     \end{subfigure}

%     \begin{subfigure}[b]{\textwidth}
%         \centering
%         \includegraphics[scale=0.85]{figs/Figure_9.png}
%         \caption{Evento após a clusterização. Agora o evento possui as duas retas corretas, a azul e vermelha.}
%         \label{subfig:depois_clustering}
%     \end{subfigure}
% \caption{Sequência de um evento em que em \ref{subfig:antes_clustering} mostra antes da clusterização e \ref{subfig:depois_clustering} mostra depois da correção. As cores das retas são arbitrárias apenas para a diferenciação.}
% \label{fig:clustering}
% \end{figure}
% \begin{figure}[H]
%     \begin{subfigure}
%         \centering
%         \includegraphics[scale=0.85]{Figure_8.png}
%         \caption{O algoritmo \ref{ransac_algo} retornou a reta vermelha, azul e verde, porém a azul e a verde devem ser uma única reta.}
%         \label{fig:exemplo_ransac_sem_clustering}
%     \end{subfigure}
%     \newline
%     \begin{subfigure}
%         \centering
%         \includegraphics[scale=0.85]{Figure_9.png}
%         \caption{Correção da saída mostrada na figura \ref{fig:exemplo_ransac_sem_clustering}. Agora temos as duas retas corretas.}
%         \label{fig:exemplo_ransac_com_clustering}
%     \end{subfigure}
% \end{figure}





% \begin{figure}[H]
%     \centering
%     \includegraphics[scale=0.85]{Figure_9.png}
%     \caption{Correção da saída mostrada na figura \ref{fig:exemplo_ransac_sem_clustering}. Agora temos as duas retas corretas.}
%     \label{fig:exemplo_ransac_com_clustering}
% \end{figure}

\par Após a etapa de clusterização é necessário classificar cada reta como sendo ou o feixe, ou uma partícula espalhada. O feixe deve incidir no TPC com um ângulo muito pequeno com relação ao versor (0, 0, 1). Além disso, mesmo se o ângulo for muito pequeno, a reta do feixe deve cruzar o plano da janela do TPC muito próximo do ponto mais provável da entrada o feixe. O ponto mais provável foi calculado usando a posição média da projeção dos pontos de uma \textit{run} no plano \textit{xy}. Disso obtemos que a posição inicial mais provável do feixe é tal que $x$ = -3.4 (6.7) mm e $y$ = -0.9 (6.3) mm. A incerteza é alta pois o feixe incide em muitas posições diferentes da janela.

\par Portanto se o ângulo entre o versor $\hat{v}_i$ de uma reta $i$ for menor que 5° (determinado de modo empírico novamente) e a distância $d$ entre o ponto $P_i$ que intercepta o plano e o ponto ($x$, $y$, 0), dados no parágrafo anterior, for menor que 15 mm (pouco mais que duas vezes a incerteza de cada ponto), então a reta é considerada como o feixe do evento. No caso de não satisfazer essas condições, então ela classificada como uma provável partícula originada da reação do feixe com o gás.

\par Importante notar que, pelo baixo ganho da parte central do \textit{micromegas}, há eventos que não possuem feixe, como mostrado na figura \ref{fig:exemplo_sem_feixe}. Neste caso é necessário assumir as propriedades da reta mais provável para o feixe, ou seja, precisa passar pelo ponto ($x$, $y$, 0) e ter versor (0, 0, 1).

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.85]{figs/Figure_12.png}
    \caption{Evento em que não foi detectado o feixe, apenas a partícula espalhada. O triângulo azul é o local calculo do vértice de reação dado pela equação \ref{eq:vertice_reacao}.}
    \label{fig:exemplo_sem_feixe}
\end{figure}

\par Nem todas as retas que não são o feixe são originadas da reação do feixe com o gás. Para determinar sua origem é necessário determinar o vértice de reação com o feixe. O vértice de reação é o ponto médio do segmento de reta que conecta a reta a ser analisada e o feixe no ponto de menor distância entre as retas. Ele permite ainda fazer correções futuras e diferençar o começo e o fim de uma reta, pois é possível determinar o ponto tal onde ocorreu uma reação.

\par Temos as seguintes equações das retas $\vec{P_1}$ e $\vec{P_2}$ como vetores:

\begin{equation}
\begin{split}
        &\vec{P_1} = \vec{A_1} + \vec{V_1} * t_1 \\
        &\vec{P_2} = \vec{A_2} + \vec{V_2} * t_2,
\end{split}
\end{equation}

onde $\vec{A_1}$ e $\vec{A_2}$ são pontos arbitrários que pertencem as retas 1 e 2, respectivamente, $\vec{V_1}$ e $\vec{V_2}$ são os versores, $t_1$ e  $t_2$ são os hiperparâmetros das retas.

\par A reta que conecta a menor distância possui versor

\begin{equation}\label{eq:versor_menor_dist}
    \vec{V_c} = \frac{\vec{V_1} \times \vec{V_2}}{\left | \vec{V_1} \times \vec{V_2} \right |}.
\end{equation}

Podemos então construir uma reta $\vec{P_3}$ que conecta $\vec{P_1}$ e $\vec{P_2}$. Essa reta deve começar no ponto de menor distância da reta 1 e terminar no ponto de menor distância da reta 2. Ou seja, temos o seguinte sistema linear:

\begin{equation*}
    \vec{A_2} + \vec{V_2} * \tilde{t_2} = \vec{A_1} + \vec{V_1} * \tilde{t_1} + \vec{V_c} * \tilde{t_3}.
\end{equation*}

Rearranjando temos que

\begin{equation}\label{eq:sistema_vertice}
    \vec{V_1} * \tilde{t_1} - \vec{V_2} * \tilde{t_2} + \vec{V_c} * \tilde{t_3} = \vec{A_2} - \vec{A_1},
\end{equation}

onde $\tilde{t_1}$, $\tilde{t_2}$ e $\tilde{t_3}$ são os hiperparâmetros a serem determinados. Caso $\vec{V_1}$ seja paralelo à $\vec{V_2}$, então não há solução (não há vértice de reação). Achando os valores, achamos os pontos de menor distância nas duas retas:

\begin{equation}
\begin{split}
        &\vec{P_1} = \vec{A_1} + \vec{V_1} * \tilde{t_1} \\
        &\vec{P_2} = \vec{A_2} + \vec{V_2} * \tilde{t_2}.
\end{split}
\end{equation}

\par Conseguimos então determinar que o vértice de reação $\vec{V_r}$ é dado por

\begin{equation} \label{eq:vertice_reacao}
    \vec{V_r} = \frac{1}{2}(\vec{P_1} + \vec{P_2}).
\end{equation}

\par Também podemos definir a distância de máxima aproximação $d_{max}$ das retas, dada pela equação \ref{eq:menor_dist_retas}.

\begin{equation} \label{eq:menor_dist_retas}
    d_{max} = \left | \vec{P_1} - \vec{P_2} \right |.
\end{equation}

% \par No caso em que $\vec{V_c}$ em \ref{eq:versor_menor_dist} é zero, então as retas analisadas são paralelas. Nesse caso não há vértice de reação e a distância de máxima aproximação é dada por

\begin{equation}
    d_{max} = \left | \left(\vec{P_1} - \vec{P_2}\right) \right |.
\end{equation}

\par Da equação \ref{eq:menor_dist_retas} podemos estabelecer um limite máximo de distância que uma reta pode ter do feixe, para então definir se houve realmente a reação no vértice de reação definido pelo equação \ref{eq:vertice_reacao}. Retas que possuíam $d_{max}$ maior ou igual que 25mm foram automaticamente descartadas.

\par Existem ainda situação em que a reta e o feixe tem uma distância de máxima aproximação muito pequena, porém o vértice de reação estava foram dos limites do TPC ($|x| < $ 140mm, $|y| < $ 140mm e $|t| < $ 512), o que também indica que a reta deve ser descartada.

\par Agora com apenas as retas certas selecionadas devemos apenas tomar cuidado de excluir eventos em que apenas o feixe foi detectado, pois neste caso não há o evento físico para ser analisado.


\section{Métodos com \textit{machine learning}}

\par Na seção \ref{sec:forcabruta} descrevemos o algoritmo completo de seleção de eventos para a análise. Agora o objetivo é aplicar algoritmos de \textit{machine learning} para melhorar o funcionamento de algo já existente ou resolver o mesmo problema de uma maneira totalmente diferente.

\subsection{Clusterização hierárquica}

\par Como queremos classificar pontos, dando \textit{labels} que diferenciem os pontos de cada reta, podemos usar algoritmos de clusterização (\textit{machine learning} não supervisionado). Devemos escolher algoritmos que sejam muito rápidos pois a ideia é substituir o uso do RANSAC. O algoritmo usado é o \textit{Hierarchical Density-Based Spatial Clustering of Applications with Noise} (HDBSCAN)\cite{hdbscan1, hdbscan2}, pois é muito eficiente em tempo e consegue realizar \textit{clustering} mesmo em dados muito complexos. O algoritmo consegue também nos dar os \textit{outliers} da \textit{pointcloud}, porém para eliminação de \textit{outliers} será usado novamente o \textit{outlier removal} do Open3D. A figura \ref{fig:cl_exs} mostra resultados do uso do algoritmo, já com as retas ajustadas. Percebe-se casos em que a houve falha na clusterização.

\begin{figure}[H]
\centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/cl_ex1.png}
        \caption{}
        \label{subfig:cl_ex1}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/cl_ex2.png}
        \caption{}
        \label{subfig:cl_ex2}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/cl_ex3.png}
        \caption{}
        \label{subfig:cl_ex3}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[scale=0.4]{figs/cl_ex4.png}
        \caption{}
        \label{subfig:cl_ex4}
    \end{subfigure}
\caption{Exemplos dos resultados para o HDBSCAN. Percebe-se que em \ref{subfig:cl_ex3} e \ref{subfig:cl_ex4} o algoritmo falhou, juntando diferentes \textit{clusters} ou simplesmente detectando ruído junto da \textit{track}.}
\label{fig:cl_exs}
\end{figure}

\par A eficiência em relação ao RANSAC é menor, pois os \textit{clusters} são pouco densos, o que dificulta a seleção de \textit{clusters} pelo algoritmo. Além disso, o algoritmo tem dificuldade em separar \textit{clusters} que possuem pontos sobrepostos, ou seja, onde há vértice de reação (vide figuras \ref{subfig:cl_ex3} e \ref{subfig:cl_ex4}). A tabela \ref{tabela:ransacvshdbscan} mostra a comparação entre a taxa de acerto e a eficiência em tempo entre o HDBSCAN e do RANSAC. A taxa de acertos mostra mostra quantos foram corretamente solucionados (ou seja, todos os \textit{clusters} foram detectados corretamente), e a eficiência mostra a capacidade de processamento de eventos pelo algoritmo, medida em eventos por segundo. O \textit{benchmark} foi feito usando o processador Ryzen 5 3600X.

\begin{table}[H]
\centering
\caption{Comparação entre algoritmos usados para identificar tracks em eventos. O HDBSCAN acerta menos vezes em comparação com o RANSAC (cerca de 14\% menos), porém é quase 4 vezes mais rápido. }
\label{tabela:ransacvshdbscan}
\begin{tabular}{|c|c|c|}
\hline
Método  & Taxa de acertos (\%) & Eficiência (eventos/s) \\ \hline
RANSAC  & 78.2                 & 57                     \\ \hline
HDBSCAN & 64.3                 & 208                    \\ \hline
\end{tabular}
\end{table}

\par A clusterização se mostrou melhor em eventos que tinham uma separação clara entre os \textit{clusters}, sem pontos que coincidem duas \textit{tracks} diferentes\cite{TriplClust}, e também nos casos em que a densidade de pontos era muito significativo. Apesar da queda na taxa de acertos a velocidade de execução sobe significativamente, sendo uma possível escolha no lugar do RANSAC.

\chapter{Resultados}

\par Após identificar todos os \textit{clusters} de cada evento devemos identificar quais são as partículas que originaram cada uma das trajetórias detectadas. Temos o comprimento de cada trajetória e sua energia, portanto o objetivo é, dada essas duas informações, identificar qual a partícula. A figura \ref{fig:coincidencia_detec} mostra um histograma bidimensional do comprimento de cada \textit{track} em função do ângulo de espalhamento no referencial do laboratório, usando apenas eventos que possuíam duas \textit{tracks} com o mesmo vértice de reação. É possível perceber as medidas coincidentes do $^{16}$O e do próton.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.75]{figs/coincidencias_tpc.png}\
    \caption{Histograma de comprimento de \textit{track} no eixo y e ângulo de espalhamento no eixo x. O histograma foi feito coletando eventos que possuíam duas trajetórias com o mesmo vértice de reação, indicando a detecção simultânea do $^{16}$O e do próton.}
    \label{fig:coincidencia_detec}
\end{figure}

\par Para determinar qual é a partícula de cada \textit{track} podemos usar o LISE++\cite{lise++} para calcular o alcance (\textit{range}) das possíveis partículas ($^{17}$F, $^{16}$O e próton) dada as propriedades do alvo ($^4$He à uma pressão de 350 Torr). A figura \ref{fig:alcance_vs_energia} mostra o alcance em mm das partículas em função da energia em MeV.

% \begin{figure}[H]
%     \centering
%     \includegraphics[scale = 0.75]{figs/alcance_vs_energia_2.png}\
%     \caption{Alcance (mm) em função da energia (MeV) para o $^{17}$F, $^{16}$O e próton. A grande diferença está no próton que tem um alcance muito maior que os outros núcleos.}
%     \label{fig:alcance_vs_energia}
% \end{figure}


\par 

% \begin{figure}[H]
%     \centering
%     \input{figs/espectrum.pgf}
%     \caption{Caption}
%     \label{fig:my_label}
% \end{figure}

\chapter{Conclusão}





% \par As duas condição que precisam ser satisfeitas para uma reta ser considerada um feixe são dadas por [XX].

% \begin{equation}\label{criterio_feixe_p}
%     \arccos{(\hat{v}_i \cdot (0, 0, 1))} < \beta, 
% \end{equation}

% onde $\hat{v}_i$ é o versor de uma reta $i$ e $\beta$ é um limiar dado em graus a ser determinado empiricamente, que neste caso foi considerado como 5°.
%\bibliography{sample}
\printbibliography[title={Referências}]
\end{document}